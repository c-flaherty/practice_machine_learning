# Practicing Deep Learning

## Iris Data Challenge 
In this algorithm, I implement a neural network on the classic IRIS dataset. Following the architecture outlined in TTIC 31230: Fundamentals of Deep Learning, Lecture 2, the network consists of: 1 hidden layer, softmax activation functions, Cross-Entropy Loss, Cross-Validation, and Stochastic Gradient Descent. In all the times that I trained and tested it, it exhibited an accuracy >90%.

## Titanic Competition
This is a Kaggle competition (https://www.kaggle.com/c/titanic/overview). 

I used a gradient boosting classifier. I cleaned data (filled in NaN's), one-hot'd categorical variables, and used performed a grid search to optimize the hyperparameters of the gradient boosing classifier.
